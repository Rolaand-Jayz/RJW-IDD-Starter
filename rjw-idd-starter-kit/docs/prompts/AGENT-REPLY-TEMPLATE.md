# AGENT REPLY TEMPLATE

Purpose
-------
This template defines the structure an AI helper (agent) must follow when producing deliverables for RJW-IDD cycles. Every reply that produces project artifacts (research summary, plan, spec, code edit instructions, test steps, etc.) must include two parallel outputs:

1. Novice Summary — plain-language, short, actionable guidance for people with no development experience.
2. Technical Specification — concrete developer-facing instructions, IDs, files, commands, diffs, and acceptance criteria.

Additionally, when the human cannot or does not want to provide technical details, the agent must auto-fill them and label those items explicitly as autogenerated assumptions with rationale and a confidence level.

How to use
----------
- Always begin by repeating the current RJW-IDD stage (Start → Explore → Decide → Create → Test → Record → Wrap).
- Provide the Novice Summary first, then the Technical Specification.
- At the end of the reply, always present:
  - the exact next prompt for the human to paste to continue, and
  - an explicit confirmation request before any invasive actions (editing files, running destructive commands).

Required structure
------------------
Follow this exact structure and headings (case-insensitive):

1) Stage Header
   - Example: "Stage: Create"

2) Novice Summary
   - One short paragraph (2–4 sentences) in plain language.
   - A 3–5 item checklist with simple actions the novice can perform.

3) Technical Specification
   - Short description (1–2 lines).
   - A list of concrete items:
     - IDs (e.g., SPEC-0001, TEST-0001)
     - Files to be edited (paths)
     - Exact commands to run (shell commands)
     - Small diffs or code snippets (plain text, copy-ready)
     - Acceptance criteria and tests (what must pass)
   - Any autogenerated content must be clearly labeled (see "Autogenerated Assumptions" below).

4) Autogenerated Assumptions (if any)
   - Each autogenerated item MUST be in this form:
     - [AUTOGENERATED ASSUMPTION] <short label>
       - Value: <the autogenerated value>
       - Rationale: <one-line reason>
       - Confidence: <High / Medium / Low>
       - How to confirm or replace: <exact prompt or human action>
   - If there are no autogenerated items, state: "No AUTOGENERATED ASSUMPTIONS."

5) Safety & Confirmation
   - List files that will be changed.
   - Ask for explicit approval: "May I proceed to apply the edits above? (yes/no)"

6) Next prompt for the human
   - Provide the exact prompt text the user should paste to accept, edit, or reject the autogenerated assumptions or proceed.

Formatting rules
----------------
- Keep Novice Summary simple and avoid jargon. Use short sentences.
- Technical Specification must be actionable and precise.
- When providing code snippets or exact changes, present them as copy-paste-ready blocks (plain text).
- Always label autogenerated content with the exact tag `[AUTOGENERATED ASSUMPTION]`.

Example conversation (complete flow)
-----------------------------------
Below is an example conversation showing how the agent should behave. The agent auto-fills missing details when the user declines to provide them.

Human:
> Stage: Start  
> I want to add a simple "health check" endpoint, but I don't know how to specify the tests or exact API path. Can you handle the details?

Agent:
Stage: Start

Novice Summary
- I will add a small web API endpoint that reports whether the app is healthy.
- I will create tests and a short description so reviewers can verify the work.
- If you want to change names later, I will tell you how.

Novice checklist:
- Read the two-sentence summary above.
- Say "yes" to let me create the files and tests.
- Or edit the suggested names below before continuing.

Technical Specification
- Goal: Add HTTP GET `/health` returning 200 and JSON `{ "status": "ok" }`.
- IDs:
  - SPEC-0003 — Health-check API
  - TEST-0007 — Health-check functional test
- Files to change/create:
  - `rjw-idd-starter-kit/tools/api/server.py` — add endpoint function
  - `rjw-idd-starter-kit/tests/test_health.py` — new test
- Commands to run:
  - `pytest rjw-idd-starter-kit/tests/test_health.py -q`
  - `python -m rjw_idd_tools.api.server` (local run)
- Minimal code to add (copy-paste ready):
  - server change (add handler):
    ```
    # rjw-idd-starter-kit/tools/api/server.py (append)
    from flask import Flask, jsonify
    app = Flask(__name__)

    @app.route("/health", methods=["GET"])
    def health_check():
        return jsonify({"status": "ok"}), 200
    ```
  - test:
    ```
    # rjw-idd-starter-kit/tests/test_health.py
    import requests
    def test_health_check():
        resp = requests.get("http://localhost:5000/health")
        assert resp.status_code == 200
        assert resp.json().get("status") == "ok"
    ```
- Acceptance criteria:
  - `pytest` passes for `TEST-0007`.
  - Running the server and curling `/health` returns JSON `{"status":"ok"}` and HTTP 200.

Autogenerated Assumptions
- [AUTOGENERATED ASSUMPTION] Framework and port
  - Value: Use Flask and port 5000 (implementation above uses Flask).
  - Rationale: Repo lacks a preferred HTTP framework; Flask is minimal and commonly available.
  - Confidence: Medium
  - How to confirm or replace: If you prefer FastAPI or a different port, reply: `Replace assumption: framework=FastAPI, port=8000`
- [AUTOGENERATED ASSUMPTION] Test harness
  - Value: Tests will call `http://localhost:5000/health` and require the server to be run separately during tests.
  - Rationale: No existing test harness was found; this is the simplest verification model.
  - Confidence: Low
  - How to confirm or replace: You can ask me to adapt the test to start the server programmatically.

Safety & Confirmation
- Files to be created/modified:
  - `rjw-idd-starter-kit/tools/api/server.py` (new or updated)
  - `rjw-idd-starter-kit/tests/test_health.py` (new)
- May I proceed to create these files and run the test locally in the environment? (yes/no)

Next prompt for the human
- To accept and continue (agent will create files and run tests):  
  Paste exactly:
  ```
  Yes — create the health endpoint and tests using the autogenerated assumptions.
  ```

If the human replies "no" or edits the assumptions, the agent must re-issue both Novice and Technical outputs reflecting the new choices, including updated autogenerated tags if any items are still filled by the agent.

Short checklist for agents (developer reminder)
----------------------------------------------
- Always produce "Novice Summary" and "Technical Specification".
- If the user cannot fully specify something, AUTOFILL with reasonable defaults and label them clearly.
- Provide confidence and a one-line rationale for each autogenerated assumption.
- Give an exact prompt the user can paste to accept, modify, or reject autogenerated items.
- Ask for explicit permission before running commands that change the repository.

Example templates (copyable)
----------------------------
Novice Summary (example):
```
Novice Summary:
- I will add a small HTTP endpoint at `/health` that returns a simple JSON status.
- I will add a test so maintainers can confirm it works.
- Say "yes" to let me create the files, or edit the names provided below to change them first.
```

Technical Specification (example):
```
Technical Specification:
- SPEC-0003: Health-check API
- Files:
  - rjw-idd-starter-kit/tools/api/server.py (new)
  - rjw-idd-starter-kit/tests/test_health.py (new)
- Commands:
  - pytest rjw-idd-starter-kit/tests/test_health.py -q
- Acceptance:
  - HTTP GET /health -> 200 and {"status":"ok"}
```

Notes
-----
- Keep replies short and structured. Novices should be able to act on the Novice Summary; experts should be able to act on the Technical Specification.
- If a reply contains both sections and proper `AUTOGENERATED` metadata, it will satisfy the repository guard checks for agent-produced artifacts.
