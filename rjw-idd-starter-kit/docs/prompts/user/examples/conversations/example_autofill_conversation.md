# Example Conversation — Agent Auto-fill & Dual Output

This example demonstrates how an AI helper (agent) should interact when a novice user cannot or chooses not to provide technical details. The agent produces two parallel outputs every time: a short "Novice Summary" (plain language) and a "Technical Specification" (developer-facing). If the user declines to answer a technical question, the agent auto-fills missing details, marks them as autogenerated, explains the rationale, and gives a confidence level.

---

Human:
> Stage: Start  
> I want to add a simple "health check" endpoint to the project so reviewers know the app is running. I don't know what framework to use or how tests should be structured. Can you handle the technical details?

Agent:
Stage: Start

## Novice Summary
- I'll add a small "health check" web endpoint that returns a simple message saying the app is OK.
- I'll also add a basic test so you or a reviewer can confirm the endpoint works.
- If you want different names or frameworks later, I will explain exactly what to change.

Novice checklist:
- Read the short summary above.
- If you agree, say the exact acceptance prompt I provide at the end.
- If you want different names (e.g., path or port), edit the autogenerated assumptions before accepting.

---

## Technical Specification
- Goal: Add an HTTP GET endpoint at `/health` that returns HTTP 200 and JSON `{ "status": "ok" }`.
- Related IDs (autogenerated if none provided):
  - SPEC-0003 — Health-check API
  - TEST-0007 — Health-check functional test
- Files to create/modify:
  - `rjw-idd-starter-kit/tools/api/server.py` — add the endpoint handler
  - `rjw-idd-starter-kit/tests/test_health.py` — add a new test
- Commands to run:
  - `pytest rjw-idd-starter-kit/tests/test_health.py -q`
  - `python -m rjw_idd_starter_kit.tools.api.server` (to run the server locally)
- Minimal code snippets (copy/paste ready):

Server snippet (append or create):
```path/to/placeholder#L1-20
from flask import Flask, jsonify

app = Flask(__name__)

@app.route("/health", methods=["GET"])
def health_check():
    return jsonify({"status": "ok"}), 200

if __name__ == "__main__":
    app.run(port=5000)
```

Test snippet (create):
```path/to/placeholder#L1-20
# rjw-idd-starter-kit/tests/test_health.py
import requests

def test_health_check():
    resp = requests.get("http://localhost:5000/health")
    assert resp.status_code == 200
    assert resp.json().get("status") == "ok"
```

- Acceptance criteria:
  - Running the server and calling `GET /health` returns HTTP 200 and JSON `{"status":"ok"}`.
  - `pytest` passes for `TEST-0007`.

---

## AUTOGENERATED ASSUMPTIONS
(These items were filled in because the human declined to supply the framework and test harness details.)

1. [AUTOGENERATED ASSUMPTION] Framework = Flask  
   - Value: Use Flask for the example server and run on port 5000.  
   - Rationale: No preferred HTTP framework found in the repo; Flask is minimal, widely available, and easy for novices.  
   - Confidence: Medium  
   - How to confirm or replace: Reply with `Replace assumption: framework=FastAPI, port=8000` (agent will regenerate the Technical Spec accordingly).

2. [AUTOGENERATED ASSUMPTION] Test model = External HTTP call  
   - Value: Tests will call `http://localhost:5000/health` and expect the server to be running separately during tests.  
   - Rationale: No test harness (e.g., test client or fixtures) detected; the external-call approach is simplest to implement for beginners.  
   - Confidence: Low  
   - How to confirm or replace: Ask the agent to adapt tests to start the server programmatically or to use a test client.

3. [AUTOGENERATED ASSUMPTION] IDs assigned  
   - Value: SPEC-0003 and TEST-0007 were chosen as new IDs.  
   - Rationale: No existing requirement/test IDs were handed to the agent; picks the next available placeholder format.  
   - Confidence: Low  
   - How to confirm or replace: Replace with your canonical IDs or request the agent to reserve real IDs with the Spec Curator.

---

## Safety & Confirmation
Files the agent will create/modify if approved:
- `rjw-idd-starter-kit/tools/api/server.py` (new or updated)
- `rjw-idd-starter-kit/tests/test_health.py` (new)

May I proceed to create the files and run the test locally? (yes/no)

---

## Next prompt (copy and paste to accept)
If you accept the autogenerated assumptions and want the agent to continue, paste the exact line below:

```
Yes — create the health endpoint and tests using the AUTOGENERATED ASSUMPTIONS above.
```

If you want to change an assumption, paste a line like one of these instead:

```
Replace assumption: framework=FastAPI, port=8000
```

or

```
Replace assumption: test_model=start_server_in_test (start the server programmatically in tests)
```

---

Human (example reply):
> Yes — create the health endpoint and tests using the AUTOGENERATED ASSUMPTIONS above.

Agent (after human confirms, Stage: Create)

## Novice Summary
- I'll create the two files and run the test. I'll tell you what I changed in two sentences when I'm done.

## Technical Specification (create actions)
- Create `rjw-idd-starter-kit/tools/api/server.py` with the snippet above.
- Create `rjw-idd-starter-kit/tests/test_health.py` with the test snippet above.
- Run the server and run the test command shown earlier; report results back in plain language and in technical detail.
- Commit message suggestion:
  - `Add health check endpoint and basic functional test (SPEC-0003, TEST-0007)`

## AUTOGENERATED ASSUMPTIONS (relisted)
- Framework = Flask (Confidence: Medium) — used to create code and tests.
- Test model = External HTTP call (Confidence: Low) — used so tests are simple to understand.

Safety & Confirmation:
- I will not edit files until you explicitly say `Apply edits now`.
- To proceed with creating files and running tests, paste:
```
Apply edits now
```

---

This example shows the required dual-output format and how autogenerated assumptions are labeled, rationalized, and given confidence levels. It also demonstrates the agent always offering exact human prompts to accept, modify, or reject autogenerated content and asking for explicit confirmation before making changes.